#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Example: Product Generation Daemon

This example demonstrates how to use the ProductGenerationDaemon to monitor
processed NetCDF files and automatically generate visualization products (PNG plots, COLMAX).
"""

import asyncio
import os
from datetime import datetime, timezone
from pathlib import Path

from radarlib import config
from radarlib.daemons import ProductGenerationDaemon, ProductGenerationDaemonConfig


def example_basic_product_daemon():
    """
    Example: Basic product generation daemon setup.

    This daemon will monitor NetCDF files generated by the ProcessingDaemon
    and automatically generate PNG plots for all fields including COLMAX.
    """
    print("=" * 60)
    print("Basic Product Generation Daemon Example")
    print("=" * 60)

    # Define volume types - same as used in download and processing daemons
    volume_types = {
        "0315": {
            "01": ["DBZH", "DBZV", "ZDR", "RHOHV", "PHIDP", "KDP"],
            "02": ["VRAD", "WRAD"],
        },
    }

    radar_name = "RMA2"
    base_path = Path(os.path.join(config.ROOT_RADAR_FILES_PATH, radar_name))

    daemon_config = ProductGenerationDaemonConfig(
        local_netcdf_dir=base_path / "netcdf",  # Where NetCDF files are located
        local_product_dir=base_path / "products",  # Where to save product files
        state_db=base_path / "state.db",  # Same database as other daemons
        volume_types=volume_types,
        radar_name=radar_name,
        poll_interval=30,  # Check every 30 seconds
        max_concurrent_processing=2,  # Process 2 volumes at a time
        product_type="image",  # Generate PNG images
        add_colmax=True,  # Generate COLMAX field
    )

    daemon = ProductGenerationDaemon(daemon_config)

    print("\nDaemon Configuration:")
    print(f"  Radar: {daemon_config.radar_name}")
    print(f"  NetCDF Dir: {daemon_config.local_netcdf_dir}")
    print(f"  Product Dir: {daemon_config.local_product_dir}")
    print(f"  State DB: {daemon_config.state_db}")
    print(f"  Poll Interval: {daemon_config.poll_interval}s")
    print(f"  Product Type: {daemon_config.product_type}")
    print(f"  Add COLMAX: {daemon_config.add_colmax}")

    print("\nStarting product generation daemon...")
    print("Press Ctrl+C to stop\n")
    print("-" * 60)

    try:
        asyncio.run(daemon.run())
    except KeyboardInterrupt:
        print("\nDaemon stopped by user")

    stats = daemon.get_stats()
    print("\n" * 60)
    print("Daemon Statistics:")
    print(f"  Volumes processed: {stats['volumes_processed']}")
    print(f"  Volumes failed: {stats['volumes_failed']}")
    print(f"  Pending volumes: {stats['pending_volumes']}")
    print(f"  Completed volumes: {stats['completed_volumes']}")
    print("=" * 60)


def example_combined_pipeline():
    """
    Example: Run all three daemons together.

    This shows how to run download, processing, and product generation daemons
    concurrently to create a complete pipeline from FTP download to visualization.
    """
    print("=" * 60)
    print("Combined Pipeline Example (Download + Processing + Products)")
    print("=" * 60)

    from radarlib.io.ftp import ContinuousDaemon, ContinuousDaemonConfig, ProcessingDaemon, ProcessingDaemonConfig

    volume_types = {
        "0315": {
            "01": ["DBZH", "DBZV", "ZDR", "RHOHV", "PHIDP", "KDP"],
            "02": ["VRAD", "WRAD"],
        },
    }

    radar_name = "RMA1"
    base_path = Path(os.path.join(config.ROOT_RADAR_FILES_PATH, radar_name))

    # Configure download daemon
    download_config = ContinuousDaemonConfig(
        host=config.FTP_HOST,
        username=config.FTP_USER,
        password=config.FTP_PASS,
        remote_base_path="/L2",
        radar_name=radar_name,
        local_bufr_dir=base_path / "bufr",
        state_db=base_path / "state.db",
        start_date=datetime(2025, 11, 24, tzinfo=timezone.utc),
        poll_interval=60,
        vol_types=volume_types,
    )

    # Configure processing daemon
    processing_config = ProcessingDaemonConfig(
        local_bufr_dir=base_path / "bufr",
        local_netcdf_dir=base_path / "netcdf",
        state_db=base_path / "state.db",
        volume_types=volume_types,
        radar_name=radar_name,
        poll_interval=30,
    )

    # Configure product generation daemon
    product_config = ProductGenerationDaemonConfig(
        local_netcdf_dir=base_path / "netcdf",
        local_product_dir=base_path / "products",
        state_db=base_path / "state.db",
        volume_types=volume_types,
        radar_name=radar_name,
        poll_interval=30,
        product_type="image",
        add_colmax=True,
    )

    download_daemon = ContinuousDaemon(download_config)
    processing_daemon = ProcessingDaemon(processing_config)
    product_daemon = ProductGenerationDaemon(product_config)

    async def run_all_daemons():
        """Run all three daemons concurrently."""
        print("\nStarting all daemons concurrently...")
        print("  - Download daemon: monitoring FTP for new BUFR files")
        print("  - Processing daemon: processing complete volumes to NetCDF")
        print("  - Product daemon: generating visualization products from NetCDF files")
        print("\nPress Ctrl+C to stop all daemons\n")
        print("-" * 60)

        tasks = [
            asyncio.create_task(download_daemon.run_service()),
            asyncio.create_task(processing_daemon.run()),
            asyncio.create_task(product_daemon.run()),
        ]

        try:
            await asyncio.gather(*tasks)
        except asyncio.CancelledError:
            print("\nAll daemons cancelled")

    try:
        asyncio.run(run_all_daemons())
    except KeyboardInterrupt:
        print("\nDaemons stopped by user")

    # Show statistics from all daemons
    download_stats = download_daemon.get_stats()
    processing_stats = processing_daemon.get_stats()
    product_stats = product_daemon.get_stats()

    print("\n" + "=" * 60)
    print("Download Daemon Statistics:")
    print(f"  Total files downloaded: {download_stats['total_downloaded']}")

    print("\nProcessing Daemon Statistics:")
    print(f"  Volumes processed: {processing_stats['volumes_processed']}")
    print(f"  Volumes failed: {processing_stats['volumes_failed']}")

    print("\nProduct Generation Daemon Statistics:")
    print(f"  Volumes processed: {product_stats['volumes_processed']}")
    print(f"  Volumes failed: {product_stats['volumes_failed']}")
    print("=" * 60)


def example_check_product_status():
    """
    Example: Check product generation status.

    Shows how to query the database to see which volumes have had products
    generated and which are pending or failed.
    """
    print("=" * 60)
    print("Product Generation Status Example")
    print("=" * 60)

    from radarlib.io.ftp import SQLiteStateTracker

    radar_name = "RMA1"
    db_path = Path(os.path.join(config.ROOT_RADAR_FILES_PATH, radar_name, "state.db"))

    if not db_path.exists():
        print(f"\nNo database found at {db_path}")
        print("Run the daemons first to create the database.")
        return

    tracker = SQLiteStateTracker(db_path)

    print(f"\nDatabase: {db_path}")

    # Get products by status
    pending = tracker.get_products_by_status("pending", "image")
    processing = tracker.get_products_by_status("processing", "image")
    completed = tracker.get_products_by_status("completed", "image")
    failed = tracker.get_products_by_status("failed", "image")

    print("\nProduct Generation Status Summary:")
    print(f"  Pending: {len(pending)}")
    print(f"  Processing: {len(processing)}")
    print(f"  Completed: {len(completed)}")
    print(f"  Failed: {len(failed)}")

    # Show volumes ready for product generation
    ready = tracker.get_volumes_for_product_generation("image")
    print(f"\nVolumes ready for product generation: {len(ready)}")

    if ready:
        print("\nNext volumes to process:")
        for i, vol in enumerate(ready[:5], 1):
            print(f"\n  {i}. {vol['volume_id']}")
            print(f"     NetCDF: {vol['netcdf_path']}")
            print(f"     Complete: {vol['is_complete'] == 1}")

    # Show completed product generations
    if completed:
        print("\nRecently completed product generations (last 5):")
        for i, prod in enumerate(completed[-5:], 1):
            print(f"\n  {i}. {prod['volume_id']}")
            print(f"     Generated: {prod['generated_at']}")

    # Show failed product generations
    if failed:
        print("\nFailed product generations:")
        for i, prod in enumerate(failed, 1):
            print(f"\n  {i}. {prod['volume_id']}")
            print(f"     Error type: {prod['error_type']}")
            print(f"     Error message: {prod['error_message'][:100]}...")

    tracker.close()
    print("\n" + "=" * 60)


def example_with_daemon_manager():
    """
    Example: Use DaemonManager to run all daemons.

    This shows the easiest way to run all three daemons together
    using the DaemonManager.
    """
    print("=" * 60)
    print("Daemon Manager Example (All Three Daemons)")
    print("=" * 60)

    from radarlib.io.ftp.daemon_manager import DaemonManager, DaemonManagerConfig

    volume_types = {
        "0315": {
            "01": ["DBZH", "DBZV", "ZDR", "RHOHV", "PHIDP", "KDP"],
            "02": ["VRAD", "WRAD"],
        },
    }

    radar_name = "RMA1"
    base_path = Path(os.path.join(config.ROOT_RADAR_FILES_PATH, radar_name))

    # Create manager configuration with all daemons enabled
    manager_config = DaemonManagerConfig(
        radar_name=radar_name,
        base_path=base_path,
        ftp_host=config.FTP_HOST,
        ftp_user=config.FTP_USER,
        ftp_password=config.FTP_PASS,
        ftp_base_path="/L2",
        volume_types=volume_types,
        start_date=datetime(2025, 11, 24, tzinfo=timezone.utc),
        download_poll_interval=60,
        processing_poll_interval=30,
        product_poll_interval=30,
        enable_download_daemon=True,
        enable_processing_daemon=True,
        enable_product_daemon=True,
        product_type="image",
        add_colmax=True,
    )

    manager = DaemonManager(manager_config)

    print("\nStarting daemon manager with all three daemons...")
    print("  - Download, Processing, and Product Generation daemons will start")
    print("  Press Ctrl+C to stop all daemons\n")

    try:
        asyncio.run(manager.start())
    except KeyboardInterrupt:
        print("\n\nStopping daemons...")
        manager.stop()
        print("All daemons stopped")

    # Show final status
    status = manager.get_status()
    print("\n" + "=" * 60)
    print("Final Status:")
    print(f"  Radar: {status['radar_code']}")

    print("\n  Download daemon:")
    print(f"    Enabled: {status['download_daemon']['enabled']}")
    if status["download_daemon"]["stats"]:
        print(f"    Files downloaded: {status['download_daemon']['stats']['total_downloaded']}")

    print("\n  Processing daemon:")
    print(f"    Enabled: {status['processing_daemon']['enabled']}")
    if status["processing_daemon"]["stats"]:
        print(f"    Volumes processed: {status['processing_daemon']['stats']['volumes_processed']}")

    print("\n  Product daemon:")
    print(f"    Enabled: {status['product_daemon']['enabled']}")
    if status["product_daemon"]["stats"]:
        print(f"    Volumes processed: {status['product_daemon']['stats']['volumes_processed']}")
    print("=" * 60)


if __name__ == "__main__":
    # Uncomment the example you want to run:

    # Basic product generation daemon
    example_basic_product_daemon()

    # Combined pipeline with all three daemons
    # example_combined_pipeline()

    # Check product generation status
    # example_check_product_status()

    # Use daemon manager for all daemons
    # example_with_daemon_manager()
